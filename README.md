<div align="center">
  
  # ğŸ“š Personal Knowledge Assistant

  <img src="assets/thumbnail.png" alt="Personal Knowledge Assistant"  />
  
  <p align="center">
    <strong>An intelligent RAG-based platform for querying books and personal knowledge</strong>
  </p>
  
  <p align="center">
    <a href="#-features">Features</a> â€¢
    <a href="#-quick-start">Quick Start</a> â€¢
    <a href="#-system-architecture">Architecture</a> â€¢
    <a href="#-backend-setup">Backend Setup</a> â€¢
    <a href="#-frontend-setup">Frontend Setup</a> â€¢
    <a href="#-usage">Usage</a> â€¢
    <a href="#-contributing">Contributing</a>
  </p>
  
  <p align="center">
    <img src="https://img.shields.io/badge/Python-3.9+-blue.svg" alt="Python Version" />
    <img src="https://img.shields.io/badge/Node.js-18+-green.svg" alt="Node.js Version" />
    <img src="https://img.shields.io/badge/FastAPI-Latest-teal.svg" alt="FastAPI" />
    <img src="https://img.shields.io/badge/Next.js-15+-black.svg" alt="Next.js" />
    <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License" />
  </p>
</div>

---

## âœ¨ Features

- ğŸ¤– **Intelligent Q&A**: Query your personal document collection using natural language
- ğŸ§  **Advanced RAG**: Confidence-based routing with knowledge strip decomposition
- ğŸ” **Smart Search**: Automatic web search fallback for low-confidence queries
- ğŸ“„ **Multi-format Support**: PDF, TXT, MD, DOCX, and PPTX document ingestion
- ğŸ¨ **Modern UI**: Beautiful, responsive chat interface with real-time math rendering
- âš¡ **Fast Retrieval**: FAISS vector store for lightning-fast document search
- ğŸŒ“ **Dark/Light Mode**: Seamless theme switching for better user experience

---

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/your-username/personal-knowledge-assistant.git
cd personal-knowledge-assistant

# Backend setup
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Add your Google API key to .env
echo "GOOGLE_API_KEY=your_key_here" > .env

# Ingest your documents
python ingest.py --dir your_books_directory

# Start backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Frontend setup (new terminal)
cd ../frontend
npm install
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to start using the application!

---

## ğŸ—ï¸ System Architecture

<div align="center">
  <img src="assets/diagram.png" alt="System Architecture" width="800" />
</div>

Our system employs a sophisticated multi-stage architecture designed for optimal knowledge retrieval and response generation:

### ğŸ”„ Document Processing Pipeline

- **ğŸ“– Document Loading**: Processes PDF documents using PyPDFLoader
- **âœ‚ï¸ Text Chunking**: Splits documents into manageable chunks using RecursiveCharacterTextSplitter
- **ğŸ”— Embedding Generation**: Converts chunks into vector representations using HuggingFaceEmbeddings
- **ğŸ’¾ Vector Storage**: Stores embeddings in a FAISS vector store for efficient retrieval

### ğŸ” Query Processing Engine

- **ğŸ”§ Query Rewriting**: Rewrites the original query to be more effective for retrieval
- **ğŸ“Š Base Retrieval**: Retrieves initial set of relevant documents from the vector store
- **ğŸ¯ Contextual Compression**: Applies filtering and extraction to improve retrieval quality

### ğŸ¯ Confidence-Based Evaluation

- **ğŸ“ˆ Document Evaluation**: Evaluates each retrieved document for relevance and reliability
- **ğŸ”¢ Score Calculation**: Combines relevance and reliability into a confidence score
- **ğŸ›¤ï¸ Confidence Routing**: Routes the query to different processing paths based on confidence:
  - **ğŸŸ¢ High Confidence (>0.7)**: Uses direct knowledge refinement
  - **ğŸŸ¡ Medium Confidence (0.3-0.7)**: Uses hybrid approach
  - **ğŸ”´ Low Confidence (<0.3)**: Falls back to web search

### ğŸ”¬ Knowledge Refinement

- **ğŸ§© Knowledge Strip Decomposition**: Breaks documents into individual "knowledge strips"
- **â­ Strip Relevance Scoring**: Scores each strip's relevance to the query
- **ğŸ·ï¸ Strip Filtering**: Filters strips based on relevance threshold

### ğŸŒ Web Search Integration

- **ğŸ” Search Query Generation**: Creates optimized search queries for low confidence scenarios
- **ğŸ¦† DuckDuckGo Search**: Performs web search using DuckDuckGo API
- **âš¡ Result Processing**: Extracts and processes relevant information from search results

### ğŸ¤– Response Generation

- **ğŸ“ Prompt Template**: Assembles a prompt with context, confidence level, and query
- **ğŸ’­ Conversation Memory**: Maintains chat history for contextual responses
- **ğŸ§  LLM Generation**: Generates final response using Google Gemini 2.0 Flash model
- **âœ¨ Response Formatting**: Formats response based on confidence level with appropriate caveats

### ğŸš€ Key Innovations

1. **ğŸ¯ Confidence-Based Routing**: Intelligently routes queries based on document relevance
2. **ğŸ§© Knowledge Strip Decomposition**: Extracts and filters relevant information pieces
3. **ğŸ”„ Dynamic Web Search Fallback**: Uses web search when document knowledge is insufficient
4. **ğŸ“Š Document Evaluation**: Explicitly evaluates document relevance and reliability
5. **ğŸ¯ Contextual Compression**: Uses embeddings filtering and LLM extraction to improve retrieval quality

---

## ğŸ“‹ Prerequisites

<table>
<tr>
<td>

**ğŸ Python 3.9+**
Backend development

</td>
<td>

**ğŸŸ¢ Node.js 18+**
Frontend development

</td>
<td>

**ğŸ“š PDF Documents**
Your knowledge base

</td>
</tr>
</table>

---

## ğŸ”§ Backend Setup

### 1. ğŸ“ Project Structure

Create and organize your project directory:

```bash
mkdir personal-knowledge-assistant
cd personal-knowledge-assistant
mkdir backend frontend
```

<details>
<summary>ğŸ“‚ <strong>View Complete Directory Structure</strong></summary>

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ chat.py         # Chat endpoints
â”‚   â”‚       â””â”€â”€ upload.py       # File upload endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration settings
â”‚   â”‚   â””â”€â”€ security.py        # Security utilities
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ vector_store.py    # Vector database operations
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag.py            # RAG implementation
â”‚   â”‚   â””â”€â”€ llm.py            # LLM service
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ text_processing.py # Text utilities
â”œâ”€â”€ data/
â”‚   â””â”€â”€ vector_store/         # FAISS index storage
â”œâ”€â”€ knowledge_base/           # Uploaded documents
â”œâ”€â”€ ingest.py                # Document ingestion script
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ .env                    # Environment variables
```

</details>

### 2. ğŸ Virtual Environment & Dependencies

```bash
cd backend
python -m venv venv

# Activate virtual environment
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate   # Windows
```

**ğŸ“¦ Install Dependencies:**

<details>
<summary>ğŸ“‹ <strong>requirements.txt</strong></summary>

```txt

```txt
fastapi>=0.104.1
uvicorn[standard]>=0.24.0
pydantic>=2.5.0
pydantic-settings>=2.1.0
langchain>=0.1.0
langchain-google-genai>=1.0.0
langchain-community>=0.0.13
langchain-huggingface>=0.0.1
faiss-cpu>=1.7.4
python-dotenv>=1.0.0
pypdf>=3.17.0
sentence-transformers>=2.2.2
python-multipart>=0.0.6
```

</details>

```bash
pip install -r requirements.txt
```

### 3. ğŸ”‘ Environment Configuration

Create a `.env` file in the backend directory:

```bash
# API Keys
GOOGLE_API_KEY=your_google_api_key_here

# Application Settings
ENVIRONMENT=development
DEBUG=true
HOST=0.0.0.0
PORT=8000

# Vector Store Settings
VECTOR_STORE_PATH=./data/vector_store
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=5
```

> **ğŸ”— Get your Google API key:**
> 1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
> 2. Create a new API key
> 3. Copy and paste it in your `.env` file

### 4. ğŸ“ Initialize Project Structure

```bash
# Create all necessary __init__.py files
touch app/__init__.py
touch app/api/__init__.py
touch app/api/routes/__init__.py
touch app/core/__init__.py
touch app/db/__init__.py
touch app/models/__init__.py
touch app/services/__init__.py
touch app/utils/__init__.py

# Create data directories
mkdir -p data/vector_store
mkdir -p knowledge_base
```

### 5. ğŸ“š Document Ingestion

```bash
# Place your PDF documents in the knowledge_base directory
cp /path/to/your/books/*.pdf knowledge_base/

# Ingest documents into the vector store
python ingest.py --dir knowledge_base
```

### 6. ğŸš€ Start the Backend Server

```bash
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

> âœ… **Backend is ready!** Your API will be available at `http://localhost:8000`

---

## ğŸ¨ Frontend Setup

### 1. ğŸ†• Initialize Next.js Project

```bash
cd ../frontend
npx create-next-app@latest . --typescript --eslint --tailwind --src-dir --app --import-alias="@/*"
```

### 2. ğŸ“¦ Install Dependencies

```bash
# Core dependencies
npm install lucide-react react-markdown framer-motion next-themes

# Math rendering
npm install katex remark-math rehype-katex

# UI components
npm install @radix-ui/react-dialog @radix-ui/react-slot class-variance-authority clsx tailwind-merge

# Additional utilities
npm install uuid @types/uuid
```

### 3. ğŸ¨ Setup shadcn/ui

```bash
npx shadcn-ui@latest init
```

**Configuration Options:**
- Style: `Default`
- Base Color: `Neutral`
- CSS variables: `Yes`

**Install UI Components:**
```bash
npx shadcn-ui@latest add button textarea card dialog alert
```

### 4. ğŸ”§ Environment Configuration

Create `.env.local` in the frontend directory:

```bash
# API Configuration
NEXT_PUBLIC_API_URL=http://localhost:8000/api

# Application Settings
NEXT_PUBLIC_APP_NAME=Personal Knowledge Assistant
NEXT_PUBLIC_APP_DESCRIPTION=Intelligent RAG-based knowledge assistant
```

### 5. ğŸš€ Start Development Server

```bash
npm run dev
```

> âœ… **Frontend is ready!** Open [http://localhost:3000](http://localhost:3000) to view your application

---

## ğŸ¯ Usage

### ğŸ“ Basic Queries

1. **ğŸ“– Document Questions**: Ask questions about your uploaded documents
   ```
   "What are the main themes in the uploaded book?"
   "Explain the concept of neural networks from the documents"
   ```

2. **ğŸ” Specific Information**: Search for specific facts or details
   ```
   "What is the definition of machine learning?"
   "List the key algorithms mentioned in chapter 5"
   ```

3. **ğŸ“Š Mathematical Concepts**: Get beautifully rendered mathematical explanations
   ```
   "Explain the backpropagation algorithm with equations"
   "What is the formula for gradient descent?"
   ```

### ğŸ¨ Features in Action

- **ğŸ¤– Smart Responses**: Confidence-based answers with source attribution
- **ğŸ” Web Search Fallback**: Automatic web search for unknown topics
- **ğŸ“Š Math Rendering**: Beautiful LaTeX equation rendering
- **ğŸŒ“ Theme Support**: Toggle between light and dark modes
- **ğŸ“± Responsive Design**: Works seamlessly on all devices

---

## ğŸ”§ Troubleshooting

<details>
<summary>ğŸ—‚ï¸ <strong>Vector Store Issues</strong></summary>

**Problem**: Vector store corruption or missing embeddings

**Solution**:
```bash
# Remove corrupted vector store
rm -rf data/vector_store

# Re-ingest documents
python ingest.py --dir knowledge_base
```

</details>

<details>
<summary>ğŸ”Œ <strong>API Connection Issues</strong></summary>

**Problem**: Frontend can't connect to backend

**Solutions**:
1. Ensure backend is running on port 8000
2. Check CORS configuration in FastAPI
3. Verify `.env.local` has correct API URL
4. Check firewall settings

</details>

<details>
<summary>ğŸ”‘ <strong>Authentication Errors</strong></summary>

**Problem**: Google API key issues

**Solutions**:
1. Verify API key in `.env` file
2. Check API key permissions
3. Ensure billing is enabled for Google AI
4. Test API key independently

</details>

---

## âš™ï¸ Customization

### ğŸ§  LLM Model Configuration

```python
# app/core/config.py
LLM_MODEL: str = "gemini-1.5-pro"  # Options: gemini-1.5-pro, gemini-1.5-flash
TEMPERATURE: float = 0.7
MAX_TOKENS: int = 2048
```

### ğŸ”§ RAG Parameters

```python
# app/core/config.py
CHUNK_SIZE: int = 1000          # Increase for larger context
CHUNK_OVERLAP: int = 200        # Reduce information loss
TOP_K_RESULTS: int = 5          # More comprehensive results
CONFIDENCE_THRESHOLD: float = 0.7  # Adjust routing sensitivity
```

### ğŸ¯ Embedding Model

```python
# app/core/config.py
EMBEDDING_MODEL: str = "sentence-transformers/all-MiniLM-L6-v2"
# Alternatives: "all-mpnet-base-v2", "all-roberta-large-v1"
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

### ğŸ”§ Development Setup

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Make your changes**
4. **Run tests**
   ```bash
   # Backend tests
   cd backend && python -m pytest
   
   # Frontend tests
   cd frontend && npm test
   ```
5. **Submit a pull request**

### ğŸ“‹ Guidelines

- Follow PEP 8 for Python code
- Use TypeScript for all new frontend code
- Add tests for new features
- Update documentation as needed
- Ensure all tests pass before submitting

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **ğŸ¤— Hugging Face** for embedding models
- **ğŸ” LangChain** for RAG framework
- **âš¡ FastAPI** for the robust backend
- **âš›ï¸ Next.js** for the amazing frontend
- **ğŸ¨ Tailwind CSS** for beautiful styling

---

<div align="center">
  <h3>Built with â¤ï¸ by <a href="https://github.com/ahammadnafiz">Ahammad Nafiz</a></h3>
  
  <p>
    <a href="https://github.com/your-username/personal-knowledge-assistant">â­ Star this project</a> â€¢
    <a href="https://github.com/your-username/personal-knowledge-assistant/issues">ğŸ› Report Bug</a> â€¢
    <a href="https://github.com/your-username/personal-knowledge-assistant/discussions">ğŸ’¬ Discussions</a>
  </p>
  
  <img src="https://img.shields.io/badge/Made%20with-â¤ï¸-red.svg" alt="Made with Love" />
  <img src="https://img.shields.io/badge/Powered%20by-AI-blue.svg" alt="Powered by AI" />
</div>
